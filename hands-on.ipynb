{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702781df-636a-40fe-aa5a-e638c2b3fd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857c0f7-e65a-4bd7-a292-832a6d2546b1",
   "metadata": {},
   "source": [
    "Hands-on with the ring test model\n",
    "=================================\n",
    "\n",
    "This notebook is meant to provide the building blocks for exploring the performance impacts of various NEURON and CoreNEURON options, using the ring test model (`ringtest.py`).\n",
    "\n",
    "This model uses a custom MOD file (`halfgap.mod`), so we must start by building `special` using this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99301d43-5710-4512-a826-6f78cbd52b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nrnivmodl mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77f4ec-2a51-4baf-8f66-2b048d3781c3",
   "metadata": {},
   "source": [
    "Now we can run the `ringtest.py` script, passing any options we want to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7099258-6377-4960-a8f0-bfc95c3e89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!x86_64/special -python ringtest.py -nt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae245a-ae6b-4a3e-9f59-8969f54a9ce1",
   "metadata": {},
   "source": [
    "The above command executed in around 0.2s on the author's machine.\n",
    "**Is that good?** *The author has no idea...*\n",
    "\n",
    "Typically when examining the performance of a new model, or an existing model on a new system, or indeed a change in software version, we need to look at trends and comparisons.\n",
    "\n",
    "To illustrate this, we will run the same model using different numbers of CPU threads.\n",
    "This is steered by the `-nt` option to `ringtest.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479299b-a7df-418e-ba76-6402d783ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ringtest(*args, repeat=3):\n",
    "    \"\"\"TODO: update ringtest.py to write these somewhere and avoid regexing\"\"\"\n",
    "    import re\n",
    "    from subprocess import check_output, STDOUT\n",
    "\n",
    "    def run():\n",
    "        out = check_output(\n",
    "            [\"./x86_64/special\", \"-python\", \"ringtest.py\"] + [str(x) for x in args],\n",
    "            shell=False,\n",
    "            stderr=STDOUT,\n",
    "            text=True,\n",
    "        )\n",
    "        m = re.search(\"runtime=([0-9\\.]+)\", out)\n",
    "        assert m\n",
    "        return {\n",
    "            \"runtime\": float(m.group(1)),\n",
    "        }\n",
    "\n",
    "    # run the measurements `repeat` times, to get a basic uncertainty estimate\n",
    "    data = [run() for _ in range(repeat)]\n",
    "    return {k: np.array([d[k] for d in data]) for k in data[0].keys()}\n",
    "\n",
    "\n",
    "# Try various powers of 2 from 1 to 64\n",
    "thread_counts = [1, 2, 4, 8, 16, 32, 64]\n",
    "# Save performance data for each thread count separately\n",
    "thread_data = {nt: ringtest(\"-nt\", nt) for nt in thread_counts}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23048b33-7f6e-4657-82b1-1ad03de35060",
   "metadata": {},
   "source": [
    "Now we have gathered the simulation runtimes for different thread values, we can plot these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf30db-ea77-45bc-baaa-afd1013db3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.xscale(\"log\", base=2)\n",
    "plt.xlabel(\"Thread count\")\n",
    "plt.ylabel(\"Simulation runtime [s]\")\n",
    "yvals, yerrs_low, yerrs_high = [], [], []\n",
    "for nt in thread_counts:\n",
    "    runtime_measurements = thread_data[nt][\"runtime\"]\n",
    "    yvals.append(runtime_measurements.mean())\n",
    "    yerrs_low.append(yvals[-1] - runtime_measurements.min())\n",
    "    yerrs_high.append(runtime_measurements.max() - yvals[-1])\n",
    "\n",
    "plt.errorbar(thread_counts, yvals, yerr=(yerrs_low, yerrs_high))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
